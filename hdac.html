<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Animation models used to compress talking-head videos at very low bitrates">
  <meta name="keywords" content="dac, hdac, rdac, animation codec, video conferencing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Animation-Based Codecs for Video Conferencing</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://l2s.centralesupelec.fr/u/konuko-goluck/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
            <a class="navbar-item" href="index.html">
                HOME
              </a>
              <a class="navbar-item" href="rdac.html">
                RDAC
              </a>
              <a class="navbar-item" href="#">
                SDAC - Coming Soon
                </a>
          <!--<a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a> -->
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">H-DAC: Hybrid coding with Deep Animation Models for Ultra-Low Bitrate Video Conferencing</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://l2s.centralesupelec.fr/u/konuko-goluck/">Goluck Konuko</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://stelat.eu/">Stéphane Lathuilière</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://l2s.centralesupelec.fr/u/valenzise-giuseppe">Giuseppe Valenzise</a><sup>3</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Université Paris-Saclay,CentraleSupélec,L2S</span>
            <span class="author-block"><sup>2</sup>IP Paris, Télécom Paris, LTCI</span>
            <span class="author-block"><sup>3</sup>Université Paris-Saclay, CNRS, CentraleSupélec, L2S</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon..)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/1QXuKGo7YjklZpKDViLUc3VnI7Odd-vaE?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->

<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Deep generative models, and particularly facial animation schemes, 
            can be used in video conferencing applications to efficiently compress 
            a video through a sparse set of keypoints, 
            without the need to transmit dense motion vectors. 
          </p>
          <p>
            While these schemes bring significant coding gains over conventional video codecs 
            at low bitrates, their performance saturates quickly when the available bandwidth 
            increases.  In this paper, we propose a layered, 
            hybrid coding scheme to overcome this limitation. 
            Specifically, we extend a codec based on facial animation by adding an auxiliary 
            stream consisting of a very low bitrate version of the video, 
            obtained through a conventional video codec (e.g., HEVC). 
          </p>
          <p>
            The animated and auxiliary videos are combined through a novel fusion module. 
            Our results show consistent average BD-Rate gains in excess of -30% 
            on a large dataset of video conferencing sequences, 
            extending the operational range of bitrates of a facial animation codec alone. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="#"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Image Animation. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Image Animation</h2>
          <p>
            Basics of image animation with unsupervised keypoints and dense motion prediction.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Scalable Base Layer. -->
      <!-- <div class="column">
        <h2 class="title is-3">Enhancement Layer</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Low-latency, low quality enhancement stream using the HEVC codec.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div> -->
    </div>
    <!--/ enhancement layer. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-4">Visual Results</h2>

        <!-- Qualitative Evaluation. -->
        <h3 class="title is-4"></h3>
        <div class="content has-text-justified">

          <p>
          <a href="https://hevc.hhi.fraunhofer.de/HM-doc/">HEVC</a> - Low latency HEVC configuration of the reference HM TEST MODEL 
          </p>

          <p>
            <a href="https://ieeexplore.ieee.org/document/9414731">DAC</a> - Our original deep animation codec 
          </p>

          <p>
            <a href="#">H-DAC</a>- Animation-based coding with the scalable enhancement layer
          </p>
          
        </div>
        <div style="display: flex; flex-direction: row">
          <div style="margin: 0px 10px 0px 30px">
            <h3>Reference</h3>
          </div>
          <div style="margin: 0px 10px 0px 60px">
            <h3>Reference+KP</h3>
          </div>
          <div style="margin: 0px 10px 0px 50px">
            <h3>Target+KP</h3>
          </div>
          <div style="margin: 0px 10px 0px 70px">
            <h3>HEVC(~10kbps)</h3>
          </div>
          <div style="margin: 0px 10px 0px 40px">
            <h3>DAC(~10kbps)</h3>
          </div>
          <div style="margin: 0px 10px 0px 50px">
            <h3>HDAC(~10kbps)</h3>
          </div>
        </div>
        <div class="column has-text-centered">
          
          <video id="matting-video" controls playsinline height="100%" autoplay loop>
            <source src="static/videos/vid_1.mp4" type="video/mp4" >
          </video>
        </div>
        <div class="column has-text-centered">
          
          <video id="matting-video" controls playsinline height="100%" autoplay loop>
            <source src="static/videos/vid_2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column has-text-centered">
          
          <video id="matting-video" controls playsinline height="100%" autoplay loop>
            <source src="static/videos/vid_3.mp4" type="video/mp4" >
          </video>
        </div>
        <div class="column has-text-centered">
          
          <video id="matting-video" controls playsinline height="100%" autoplay loop>
            <source src="static/videos/vid_4.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Quantitative. -->
        <!-- <h3 class="title is-4"></h3>
        <div class="content has-text-justified">
          <p>
            Quantitative measures for ultra-low bitrate video coding
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="#"
                  class="interpolation-image"
                  alt="Interpolate start reference image."/>
            <p>Rate-Distortion Curve</p>
          </div>
          <div class="column is-3 has-text-centered">
            <img src="#"
                  class="interpolation-image"
                  alt="subjective evaluation curve."/>
            <p>Subjective Evaluation</p>
          </div>
          <div class="column is-3 has-text-centered">
            <img src="#"
                  class="interpolation-image"
                  alt="table with PCC and ROCC."/>
            <p class="is-bold">Metric Correlation Performance</p>
          </div>
        </div>
        <br/> -->


      </div>

    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There is a number of works released concurrent or subsequent to our initial work in the domain of animation-based video communication. 
            They provide valuable insight into computer-vision and model optimization aspects that
            could inspire great curiousity into this line of work.
          </p>
          
          <p>
            <a href="https://nvlabs.github.io/face-vid2vid/">Face-vid2vid:</a> Proposes a neural talking-head video synthesis model with novel-view rendering capability and demonstrates its application to video conferencing.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2012.00328">Motion-SPADE</a> Explores quality and bandwidth trade-offs for approaches based on static landmarks, dynamic landmarks or segmentation maps for image animation and proposes designs for mobile-compatible model architecture for low-latency chat applications.
          </p>
          <p>
            <a href="https://github.com/alibaba-edu/temporal-evolution-inference-with-compact-feature-representation-for-talking-face-video-compression">Beyond Keypoint Coding: Temporal Evolution Inference with Compact Feature Representation for Talking Face Video Compression</a>
            Proposes a novel sparse representation for animation-based coding. We updated our own keypoint quantization and entropy coding processes to match those used by this work.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{konuko2022hdac,
  author    = {Konuko, Goluck and Lathuilière, Stéphane and Valenzise, Giuseppe},
  title     = {H-DAC: Hybrid coding with Deep Animation Models for Ultra-Low Bitrate Video Conferencing},
  journal   = {ICIP},
  year      = {2022},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="#">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/Goluck-Konuko" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <!-- <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p> -->
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
